---
title: "Solo Exploration in R"
output:
  pdf_document: default
  html_notebook: default
---

## Tidyverse Solo Exercise

In this project, you'll practice working with data using the tidyverse libraries. You'll be working with data on each of 145 school districts and the State of Tennessee. This data contains, for the 2014-2015 school year:

-   Proficiency rates on state tests
-   Student demographics
-   Chronic absenteeism
-   Discipline (suspension, expulsion) rates
-   High school graduation, dropout rates
-   Average ACT composite scores
-   A region in Tennessee


```{r}
library(tidyverse)
library(scales)
```


Create an RMarkdown file to answer the following questions.

> done!

1.  Read in districts.csv into a tibble named districts. How many rows and columns does it contain?

> 146 rows, 27 columns

```{R}
districts <- read_csv('../data/districts.csv')

# some ways to access that info
nrow(districts)
ncol(districts)
```

2.  Notice that the first row corresponds to the whole State of Tennessee. Remove this row and save the result back to districts.

```{R}
districts <- districts %>%
    filter(system_name != 'State of Tennessee')

```

3.  How many districts have a proficiency rate of at least 80% for both alg_1 and eng_1?

> 13 districts

```{R}
districts %>% 
  filter(alg_1 >= 80 & eng_1 >=80) %>% 
  #count()
  nrow()
```

4.  How many districts have a proficiency rate less than 50% for either alg_1 or eng_1?

> 8 districts

```{r}
districts %>% 
  filter(alg_1 < 50 | eng_1 < 50) %>% 
  #count()
  #summarize(n())
  nrow()
```

5.  Which district has the lowest graduation rate?

> Tenn School for Blind

```{r}
districts %>%
    #filter(grad == min(grad, na.rm=TRUE))
    slice_min(grad, n=1) %>% 
    select(system_name)
```

6.  Within the Mid Cumberland region, which district has the highest ACT composite?

> Williamson County

```{r}
districts %>% 
  filter(region == 'Mid Cumberland')  %>% 
  #filter(act_composite == max(act_composite, na.rm=TRUE))
  slice_max(act_composite, n=1)
```

7.  Create a histogram showing the distribution of graduation rates. What can you say about this distribution?

> the majority of schools/districts have about a 90% graduation rate. There are a few outliers with much lower graduation numbers

```{r}
# this works, but it's nicer to use pipes!
#ggplot(districts, aes(x=grad)) +
#  geom_histogram(binwidth=3)

districts %>%
  ggplot(aes(x=grad, fill=region)) +
  geom_histogram(binwidth=3, na.rm=TRUE)
```

8.  Create a scatter plot to compare alg_1 proficiency rates to alg_2 rates. What do you notice?

> there seems to be a linear relationship , I.e., the higher grades in alg_1 proficiency seem to indicate higher rates in alg_2 proficiency overall

```{r}
districts %>% 
  ggplot(aes(x=alg_1, y=alg_2, color=region)) +
  geom_point(na.rm=TRUE) +
  xlim(0,100) +
  ylim(0,100)
```

8.  part 2 - Facet this plot by region. Does anything stand out when you facet the plots?

> Upper Cumberland seems to stand out as being completely different from the rest.

```{r}
districts %>% 
  ggplot(aes(x=alg_1, y=alg_2, color=region)) +
  facet_wrap(vars(region)) +
  geom_point(na.rm=TRUE) +
  xlim(0,100) +
  ylim(0,100) 
```

9.  Create a bar chart showing the total enrollment by region. Which region has the highest total enrollment? Which has the smallest?

> Mid Cumberland has highest totla enrollment, Northwest has the smallest.

```{r}
districts %>% 
  ggplot(aes(y=region, weight=enrollment, fill=region)) +
  geom_bar() +
  scale_x_continuous(labels = comma)
  # this last one is from scales library, to get rid of scientific notation
```

10. When creating this bar chart you may have noticed that some districts have missing enrollment values. For how many districts is this the case?

> that is true for 4 districts

```{r}
districts %>% 
  filter(is.na(enrollment))
```

11. What is the mean graduation rate across all districts? What might be wrong with using just the regular mean to assess average graduation rates?

> mean graduation rate is 90.1%, problem with it is that it essentially captures most schools, centered around the peak. In other words, it essentially excludes the 7 schools with graduation rates less than 80%, in some cases much less. Furthermore, this does not account for how many kids are enrolled in each school

```{r}
districts %>% 
  summarize(mean = mean(grad, na.rm=TRUE),
            median = median(grad, na.rm=TRUE),
            sd = sd(grad, na.rm=TRUE))
```

```{r}
districts %>% 
  filter(grad < 80)
```

12. Redo the previous question but use a weighted average (weighted.mean) graduation across all districts, weighing by enrollment. How much does this change your answer? Can you explain using the data the reason for the big change from using the mean?

> in order to calculate weighted mean I had to remove rows that had NA for graduate, OR for enrollment. The mean dropped by almost 3%. That is because of two of the districts in particular with large enrollment, Shelby County and Davidson County

```{r}
districts %>% 
  drop_na(grad, enrollment) %>% 
  summarize(w_mean = weighted.mean(grad, enrollment),
            sd = sd(grad))
```
```{r}
districts %>% 
  filter(grad < 80) %>% 
  summarize(sum(enrollment, na.rm=TRUE))
```
> commenting the filter line, I get the total number of enrolled students over all districts, 943673. The regions that had less than 80% in particular have 198855 enrolled, so roughly 21% of all enrolled!

13. Create a boxplot showing graduation rates per region. Does anything stand out?

> Upper Cumberland, Southwest/Memphis, Northwest each have 1 outlier, Mid Cumberland has 2 (one particularly extreme as seen previously). On top of that, Southwest/Memphis in particular has a large distribution of graduation values

```{r}
districts %>% 
  ggplot(aes(x=grad, y=region, fill=region)) +
  geom_boxplot(na.rm=TRUE) +
  scale_x_continuous(breaks=seq(0,100,5))
```
14. Find the weighted average of graduation rates by region using enrollment as weights. Compare the results you get for the weighted average to what you see from the boxplots.

> certain regions, but in particular Southwest/Memphis's outliers heavily influence the weighted mean

```{r}
districts %>% 
  drop_na(grad, enrollment) %>% 
  group_by(region) %>% 
  summarize(w_mean = weighted.mean(grad, enrollment),
            mean = mean(grad))
```

15. For many districts, values for alg_2 are lower than for alg_1. Create a histogram showing the distribution of differences (alg_1 - alg_2).

```{r}
districts %>% 
  mutate(alg_diff=alg_1 - alg_2) %>% 
  ggplot(aes(x=alg_diff, fill=region)) +
  geom_histogram(binwidth=5, na.rm=TRUE) +
  facet_wrap(~region)
```
15. cont - Which school had the largest drop from alg_1 to alg_2? 

> Pickett County

```{r}
districts %>% 
  mutate(alg_diff=alg_1 - alg_2) %>% 
  filter(alg_diff == max(alg_diff, na.rm=TRUE)) %>% 
  # alternatively to filter
  # slice_max(alg_dif, n = 1)
  select(system_name, alg_diff, alg_1, alg_2)
```
15. cont - For what percentage of schools is it true that alg_2 is larger than alg_1?

> 18 schools (out of 145), so 12.4% (i got this simply by filtering where alg_2 > alg_1); or 15.3% if removed NA

```{r}
districts %>% 
  mutate(alg_diff=alg_1 - alg_2) %>% 
  summarize(mean(alg_diff<0, na.rm=TRUE))
```
15. cont - Is there a similar drop off for eng_2 and eng_3?

> It's even worse! Only Bradford SSD has eng 3 higher than eng 2, similar distributions

```{r}
#districts %>% 
#  filter(eng_3 > eng_2)

#districts %>% 
#  mutate(eng_diff=eng_2 - eng_3) %>% 
#  summarize(mean(eng_diff<0, na.rm=TRUE))

districts %>% 
  mutate(eng_diff=eng_2 - eng_3) %>% 
  ggplot(aes(x=eng_diff, fill=region)) +
  geom_histogram(binwidth=5, na.rm=TRUE) +
  facet_wrap(~region)
```
16. You may have noticed that a lot of rows are missing values. Which district has the largest number of missing values?

> West Tenn School for Deaf has 15 missing values.

```{r}
count_na_func <- function(x) sum(is.na(x)) 

districts %>% 
  # note the 1 in apply is to do over rows (2 would be columns)
  mutate(count_na = apply(., 1, count_na_func)) %>% 
  filter(count_na == max(count_na))

# alternative
#districts %>% 
#  mutate(nancount = rowSums(is.na(.))) %>% 
#  filter(nancount >= 5) %>% 
#  arrange(desc(nancount))
```
16. cont - What do you notice about schools that have a lot of missing values?

> first looked at how many schools have which data missing. Most schools (112) don't have any missing, and an additional 13 have only 1 or two values missing. From there, the next one has 6 missing and going up from there. I decided to inspect all schools with 6 or more values missing.

> they include special district schools (for kids with special needs) and certain city schools

```{r}
districts %>% 
  mutate(count_na = apply(., 1, count_na_func)) %>% 
  group_by(count_na) %>% 
  summarize(n())
```
```{r}
districts %>% 
  mutate(count_na = apply(., 1, count_na_func)) %>% 
  filter(count_na >= 6)
```
17. Find the correlation between graduation rate and all other variables. Create a horizontal bar chart showing these correlations. Make sure that your plot is ordered by correlation values. What do you notice from these correlations?

> dropout seems to have the biggest negative correlation to grad, suspended second one

```{r}
districts %>% 
  select(where(is.numeric)) %>% 
  cor(x=., y=districts$grad, use='complete.obs') %>% 
  as.data.frame() %>% 
  rownames_to_column(var = 'variables') %>% 
  ggplot(aes(y=reorder(variables, V1), weight=V1)) +
  geom_bar() 
```


18. Create a scatterplot for grad vs. suspended. Does what you see make sense given your answer from the previous part?

> not really; I mean, there could perhaps be a slight downwards trend with more suspensions, but only after about 5%

```{r}
districts %>% 
  ggplot(aes(x=suspended, y=grad, color=region)) +
  geom_point(na.rm=TRUE)
```


19. Create a linear regression model using lm with target variable grad and predictor variable suspended. What R\^2 value does this model have? What is the interpretation of this number?

> the R squared is 0.0722, very close to 0, so the linear fit does not match up to the data well, lot of variability
> anova also tells us that the P-value is low, 0.001262 and therefore it's better to predict with one variable than with none (with constant), so it's statistically significant

```{r}
simple_linear <- lm(grad ~ suspended, data = districts)

anova(simple_linear)
summary(simple_linear)
```

note: there is one extreme value outlier (low grad rate AND low suspension rate ), TN school for blind. If we remove it, the numbers improve significantly, and the coefficients are different.

```{r}
grad_lm <- districts %>% 
  filter(grad > 25) %>% 
  lm(grad ~ suspended, data = .)

anova(grad_lm)
summary(grad_lm)
```


20. Add the regression line to your scatterplot using geom_smooth with method='lm'. How do you feel about the regression line after seeing it plotted on the scatterplot?

> not the worst line I've seen, but the residuals are increasing

```{r}
districts %>% 
  ggplot(aes(x=suspended, y=grad)) +
  geom_point(na.rm=TRUE) +
  geom_smooth(method ='lm', na.rm=TRUE)
```


### Continued Exploration and Practice

21. Read in the school-level testing data for 2014, available here (<https://www.tn.gov/content/dam/tn/education/data/data_2014_school_base.xlsx>). You might find the readxl library useful for this task. If you use this library, be sure to look at the na argument for the read_excel function.

```{r}
library(readxl)

school_testing <- read_excel('../data/data_2014_school_base.xlsx', na='na')
```


22. How many schools have at least 20 percent of students below bsc for Algebra I? Which districts do these schools belong to?

> not sure I'm understanding this q. corretly. But I think the answer is 372 (if we look for all grades, and not separately, as well as if we look for all students, and not separately)

```{r}
school_testing %>% 
  filter(subject == 'Algebra I' & grade == 'All Grades' & subgroup == 'All Students') %>% 
  filter(pct_bsc_and_below >= 20) %>% 
  count()
```


23. How many schools have at least 20 percent of students below bsc for both Algebra I and English I?

> same doubts as above, the result now being 303 shools. The way I did it was to first filter down to all schools with Algebra below 20. And then use those schools, filtering further by English below 20

```{r}
school_algebra_below20 <- school_testing %>% 
  filter(subject == 'Algebra I' & grade == 'All Grades' & subgroup == 'All Students') %>% 
  filter(pct_bsc_and_below >= 20) %>% 
  select(school_name)
```

```{r}
school_algebra_below20 %>% 
  left_join(school_testing, by='school_name') %>% 
  filter(subject == 'English I' & grade == 'All Grades' & subgroup == 'All Students') %>% 
  filter(pct_bsc_and_below >= 20)
```


24. Which grade has the highest pct_adv for Algebra I? Plot the average pct_adv per grade level as a bar chart. Make sure that the bars are ordered by grade level.

```{r}
school_testing %>% head()
```


```{r}
school_testing %>% 
  filter(subject == 'Algebra I') %>%
  filter(pct_adv != '*' & pct_adv != '**') %>% 
  #group_by(grade) %>% 
  summarize(sum(pct_adv, na.rm=TRUE))
  #slice_max(pct_adv, n=1)
```


25. Find the correlation between pct_adv for Algebra I and pct_adv for Algebra II by school. Create a scatterplot showing Algebra II scores vs. Algebra I scores by school.

26. Find all schools in Rutherford County that have "High School" in their name. For these schools, create a chart (your choice) showing the differences in pct_below_bsc, pct_bsc, pct_prof, and pct_adv for Algebra I when looking across all subgroups and grades.

27. I claim that smaller schools do a better job preparing students for Algebra I standardized tests. Find the average number of valid tests (a proxy for the school size) for schools where the pct_prof_adv for Algebra I is greater than 95. Compare this to the average number of valid tests for all schools. In light of this result, how does my claim look?

28. I also claim that smaller schools do a worse job preparing students for Algebra I standardized tests. Find the average number of valid tests (a proxy for the school size) for schools where the pct_prof_adv for Algebra I is less than 25. Compare this to the average number of valid tests for all schools. In light of this result, how does my claim look now?

29. Create a scatterplot showing pct_prov_adv vs. valid_tests. Can you use this to explain the result for the previous two questions?

If you finish all of the above questions, continue to explore the two datasets and see what else interesting you can find.

Also, check out the plotly library for R. The ggplotly function makes it very easy to convert ggplot plots into interactive plotly plots.
